# -*- coding: utf-8 -*-
"""Tarea2_IA

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pbeLwnl-b2qrsbDLLPz_5Ec_Sx2mFpzt

# Universidad de O'Higgins

## Escuela de Ingeniería
## COM4402: Introducción a Inteligencia Artificial

### **Tarea 2: Clasificación de Dígitos Manuscritos con Redes Neuronales**

### Estudiante: Bastián Rubio Moya.

El objetivo de esta tarea es utilizar redes neuronales en un problema de clasificación de dígitos. Se utilizará el conjunto de datos Optical Recognition of Handwritten Digits Data Set. Este conjunto tiene 64 características, con 10 clases y 5620 muestras en total. La base de datos estará disponible en U-Campus.

Las redes a ser entrenadas tienen la siguiente estructura: capa de entrada de dimensionalidad 64 (correspondiente a los datos de entrada), capas ocultas (una o dos) y capa de salida con 10 neuronas y función de activación softmax. La función de loss (pérdida) es entropía cruzada. El optimizador que se
debe usar es Adam. La función softmax está implícita al usar la función de pérdida CrossEntropyLoss de PyTorch (**no se debe agregar softmax a la salida de la red**).

Se usará PyTorch para entrenar y validar la red neuronal que implementa el clasificador de dígitos. Se analizará los efectos de cambiar el tamaño de la red (número de capas ocultas y de neuronas en estas
capas) y la función de activación.

El siguiente código base debe ser usado para realizar las actividades pedidas.
"""

import pandas as pd
import torch
import torch.nn as nn
import numpy as np
import time
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, accuracy_score
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

"""## Subir datasets de dígitos (train)"""

#Descargar Archivos
!wget https://raw.githubusercontent.com/Felipe1401/Mineria/main/dataset_digits/1_digits_train.txt
!wget https://raw.githubusercontent.com/Felipe1401/Mineria/main/dataset_digits/1_digits_test.txt

"""## Leer dataset de dígitos"""

column_names = ["feat" + str(i) for i in range(64)]
column_names.append("class")

df_train_val = pd.read_csv('1_digits_train.txt', names = column_names)
df_train_val

df_test = pd.read_csv('1_digits_test.txt', names = column_names)
df_test

df_train, df_val = train_test_split(df_train_val, test_size = 0.3, random_state = 10)

scaler = StandardScaler().fit(df_train.iloc[:,0:64])
df_train.iloc[:,0:64] = scaler.transform(df_train.iloc[:,0:64])
df_val.iloc[:,0:64] = scaler.transform(df_val.iloc[:,0:64])
df_test.iloc[:,0:64] = scaler.transform(df_test.iloc[:,0:64])

df_train

"""## Crear datasets y dataloaders para pytorch (train)"""

# Crear datasets
feats_train = df_train.to_numpy()[:,0:64].astype(np.float32)
labels_train = df_train.to_numpy()[:,64].astype(int)
dataset_train = [ {"features":feats_train[i,:], "labels":labels_train[i]} for i in range(feats_train.shape[0]) ]

feats_val = df_val.to_numpy()[:,0:64].astype(np.float32)
labels_val = df_val.to_numpy()[:,64].astype(int)
dataset_val = [ {"features":feats_val[i,:], "labels":labels_val[i]} for i in range(feats_val.shape[0]) ]

feats_test = df_test.to_numpy()[:,0:64].astype(np.float32)
labels_test = df_test.to_numpy()[:,64].astype(int)
dataset_test = [ {"features":feats_test[i,:], "labels":labels_test[i]} for i in range(feats_test.shape[0]) ]

# Crear dataloaders
dataloader_train = torch.utils.data.DataLoader(dataset_train, batch_size=128, shuffle=True, num_workers=0)
dataloader_val = torch.utils.data.DataLoader(dataset_val, batch_size=128, shuffle=True, num_workers=0)
dataloader_test = torch.utils.data.DataLoader(dataset_test, batch_size=128, shuffle=True, num_workers=0)

"""## Entrenamiento"""

def trainning(model):
  start = time.time()

  # Guardar resultados del loss y epocas que duró el entrenamiento
  loss_train = []
  loss_val = []
  epochs = []

  # Guardar el tiempo transcurrido en cada época
  time_points = []

  # Variables para el early stopping
  best_loss_val = 10000000000000
  patience = 10 #Número de epoch para esperar antes que termine el entrenamiento
  wait = 0 #Contador de espera

  # Entrenamiento de la red por n epocas
  for epoch in range(1000):

    # Guardar loss de cada batch
    loss_train_batches = []
    loss_val_batches = []

    # Entrenamiento --------------------------------------------------------------
    model.train()
    # Debemos recorrer cada batch (lote de los datos)
    for i, data in enumerate(dataloader_train, 0):
      # Procesar batch actual
      inputs = data["features"].to(device) # Características
      labels = data["labels"].to(device)   # Clases
      # zero the parameter gradients
      optimizer.zero_grad()
      # forward + backward + optimize
      outputs = model(inputs)           # Predicciones
      loss = criterion(outputs, labels) # Loss de entrenamiento
      loss.backward()                   # Backpropagation
      optimizer.step()

      # Guardamos la pérdida de entrenamiento en el batch actual
      loss_train_batches.append(loss.item())

    # Guardamos el loss de entrenamiento de la época actual
    loss_train.append(np.mean(loss_train_batches)) # Loss promedio de los batches


    # Predicción en conjunto de validación ---------------------------------------
    model.eval()
    with torch.no_grad():
      # Iteramos dataloader_val para evaluar el modelo en los datos de validación
      for i, data in enumerate(dataloader_val, 0):
        # Procesar batch actual
        inputs = data["features"].to(device) # Características
        labels = data["labels"].to(device)   # Clases

        outputs = model(inputs)              # Obtenemos predicciones

        # Guardamos la pérdida de validación en el batch actual
        loss = criterion(outputs, labels)
        loss_val_batches.append(loss.item())

    # Guardamos el Loss de validación de la época actual
    loss_val.append(np.mean(loss_val_batches)) # Loss promedio de los batches
    # Guardamos la época
    epochs.append(epoch)

    # Guardamos el tiempo transcurrido
    time_points.append(time.time() - start)

    # Imprimir la pérdida de entrenamiento/validación en la época actual
    print(("Epoch: %d, train loss: %.4f, val loss: %.4f"  %(epoch, loss_train[epoch], loss_val[epoch])))

    # Early-stopping
    if(loss_val[epoch] < best_loss_val): #Si la perdida de la epoch es menor que la mejor perdida global, la reasignamos y reiniciamos el contador
      best_loss_val = loss_val[epoch]
      wait = 0
    else: #En caso contrario se suma el contador
      wait += 1

    #print(f"wait: {wait}, best_loss_val: {best_loss_val}") <- Descomentar para ver como funciona
    #Si el contador supera (o iguala) la paciencia se activa el early-stopping
    if (wait >= patience):
      print(f"Se activo el early-stopping en la época {epoch}")
      break

  # Matriz de confusión Entrenamiento -------------------------------------------------------------------------------

  # Calcular la matriz de confusión y accuracy normalizado en el conjunto de entrenamiento
  model.eval()
  with torch.no_grad():
      # Preparar los datos de entrenamiento
      labels_train = []
      predictions_train = []

      for i, data in enumerate(dataloader_train, 0):
          inputs = data["features"].to(device)
          labels = data["labels"].to(device)

          outputs = model(inputs)
          _, predicted = torch.max(outputs, 1)

          labels_train.extend(labels.cpu().numpy())
          predictions_train.extend(predicted.cpu().numpy())

  # Calcular la matriz de confusión en el conjunto de entrenamiento
  confusion_matrix_normalized_train = confusion_matrix(labels_train, predictions_train, normalize='true')

  # Calcular el accuracy normalizado en el conjunto de entrenamiento
  accuracy_normalized_train = accuracy_score(labels_train, predictions_train)



  # Matriz de confusión Validación -------------------------------------------------------------------------------

  # Calcular la matriz de confusión y accuracy normalizado en el conjunto de validación
  model.eval()
  with torch.no_grad():
      # Preparar los datos de validación
      val_labels = []
      val_predictions = []

      for i, data in enumerate(dataloader_val, 0):
          inputs = data["features"].to(device)
          labels = data["labels"].to(device)

          outputs = model(inputs)
          _, predicted = torch.max(outputs, 1)

          val_labels.extend(labels.cpu().numpy())
          val_predictions.extend(predicted.cpu().numpy())

  end = time.time()
  print('Finished Training, total time %f seconds' % (end - start))

  # Calcular la matriz de confusión en el conjunto de validación
  confusion_matrix_normalized_val = confusion_matrix(val_labels, val_predictions, normalize='true')

  # Calcular el accuracy normalizado en el conjunto de validación
  accuracy_normalized_val = accuracy_score(val_labels, val_predictions)

  # Mostrar la matriz de confusión en el conjunto de entrenamiento con colores
  plt.figure(figsize=(8, 6))
  sns.heatmap(confusion_matrix_normalized_train, annot=True, cmap='Blues', cbar=False)
  plt.xlabel('Clase Predicha')
  plt.ylabel('Clase Verdadera')
  plt.title(f'Matriz de Confusión Normalizada en Entrenamiento (Accuracy = {accuracy_normalized_train:.2f})')
  plt.show()

  # Mostrar la matriz de confusión en el conjunto de validación con colores
  plt.figure(figsize=(8, 6))
  sns.heatmap(confusion_matrix_normalized_val, annot=True, cmap='Blues', cbar=False)
  plt.xlabel('Clase Predicha')
  plt.ylabel('Clase Verdadera')
  plt.title(f'Matriz de Confusión Normalizada en Validación (Accuracy = {accuracy_normalized_val:.2f})')
  plt.show()

  # Graficar el loss de entrenamiento y el de validación en función del tiempo
  plt.figure()
  plt.plot(time_points, loss_train, 'b',label='Training Loss')
  plt.plot(time_points, loss_val, 'r',label='Validation Loss')
  plt.xlabel('Tiempo (segundos)')
  plt.ylabel('Loss')
  plt.legend()
  plt.title('Curvas de Loss en función del tiempo')
  plt.show()

"""## Crear modelos

Creación de distintos modelos a comparar
"""

#Modelo 1
#10 neuronas en la capa oculta, usando función de activación ReLU
model1 = nn.Sequential(
          nn.Linear(64, 10), #Capa de entrada con 64 caracteristicas y 10 neuronas
          nn.ReLU(),         #Función de activación ReLU
          nn.Linear(10,10)   #Capa oculta con 10 neuronas y 10 de salida
        )


#Funciones de los modelos
device = torch.device('cuda')
model1 = model1.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model1.parameters(), lr=1e-3)

#Entrenar
trainning(model1)

#Modelo 2
#40 neuronas en la capa oculta y función de activación ReLU
model2 = nn.Sequential(
          nn.Linear(64, 40), #Capa de entrada con 64 caracteristicas y 40 neuronas
          nn.ReLU(),         #Función de activación ReLU
          nn.Linear(40,10)   #Capa oculta con 40 neuronas y 10 de salida
        )

#Funciones de los modelos
device = torch.device('cuda')
model2 = model2.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model2.parameters(), lr=1e-3)

#Entrenar
trainning(model2)

#Modelo 3
#10 neuronas en la capa oculta y función de activación Tanh
model3 = nn.Sequential(
          nn.Linear(64, 10), #Capa de entrada con 64 caracteristicas y 10 neuronas
          nn.Tanh(),         #Función de activación ReLU
          nn.Linear(10,10)   #Capa oculta con 10 neuronas y 10 de salida
        )

#Funciones de los modelos
device = torch.device('cuda')
model3 = model3.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model3.parameters(), lr=1e-3)

#Entrenar
trainning(model3)

#Modelo 4
#40 neuronas en la capa oculta y función de activación Tanh
model4 = nn.Sequential(
          nn.Linear(64, 40), #Capa de entrada con 64 caracteristicas y 40 neuronas
          nn.Tanh(),         #Función de activación ReLU
          nn.Linear(40,10)   #Capa oculta con 40 neuronas y 10 de salida
        )
#Funciones de los modelos
device = torch.device('cuda')
model4 = model4.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model4.parameters(), lr=1e-3)

#Entrenar
trainning(model4)

#Modelo 5
#2 capas ocultas con 10 y 10 neuronas cada una y función de activación ReLU
model5 = nn.Sequential(
          nn.Linear(64,10), #Capa de entrada con 64 caracteristicas y 10 neuronas
          nn.ReLU(),        #Función de activación ReLU
          nn.Linear(10,10), #Segunda capa oculta con 10 neuronas
          nn.ReLU(),        #Función de activación ReLU
          nn.Linear(10,10)  #Capa de salida 10 neuronas
        )

#Funciones de los modelos
device = torch.device('cuda')
model5 = model5.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model5.parameters(), lr=1e-3)

#Entrenar
trainning(model5)

#Modelo 6
#2 capas ocultas con 40 y 40 neuronas cada una y función de activación ReLU
model6 = nn.Sequential(
          nn.Linear(64,40), #Capa de entrada con 64 caracteristicas y 40 neuronas
          nn.ReLU(),        #Función de activación ReLU
          nn.Linear(40,40), #Segunda capa oculta con 40 neuronas
          nn.ReLU(),        #Función de activación ReLU
          nn.Linear(40,10)  #Capa de salida 40 neuronas
        )

#Funciones de los modelos
device = torch.device('cuda')
model6 = model6.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model6.parameters(), lr=1e-3)

#Entrenar
trainning(model6)

"""###P3) Usando la mejor red encontrada en validación (aquella con mayor accuracy en validación), calcular la matriz de confusión normalizada y el accuracy normalizado, usando el conjunto de prueba.

"""

#Modelo 4
#40 neuronas en la capa oculta y función de activación Tanh
with torch.no_grad():
    test_labels = []
    test_predictions = []

    for i, data in enumerate(dataloader_test, 0):
        inputs = data["features"].to(device)
        labels = data["labels"].to(device)

        outputs = model4(inputs)
        _, predicted = torch.max(outputs, 1)

        test_labels.extend(labels.cpu().numpy())
        test_predictions.extend(predicted.cpu().numpy())

# Calcular la matriz de confusión en el conjunto de prueba
confusion_matrix_normalized_test = confusion_matrix(test_labels, test_predictions, normalize='true')

# Calcular el accuracy normalizado en el conjunto de prueba
accuracy_normalized_test = accuracy_score(test_labels, test_predictions)

# Mostrar la matriz de confusión en el conjunto de prueba con colores
plt.figure(figsize=(8, 6))
sns.heatmap(confusion_matrix_normalized_test, annot=True, cmap='Blues', cbar=False)
plt.xlabel('Clase Predicha')
plt.ylabel('Clase Verdadera')
plt.title(f'Matriz de Confusión Normalizada en Prueba (Accuracy = {accuracy_normalized_test:.2f})')
plt.show()